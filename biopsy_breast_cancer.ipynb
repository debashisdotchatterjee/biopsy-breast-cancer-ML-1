{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/V5lbefqJ7WsUypV8i77e",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debashisdotchatterjee/biopsy-breast-cancer-ML-1/blob/main/biopsy_breast_cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgqRNj47gqZc",
        "outputId": "eaf24bdf-7f91-4b77-d1a1-bf40a4bbc488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydataset in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pydataset) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->pydataset) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas numpy matplotlib seaborn scikit-learn statsmodels\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nbEeTEXulQE",
        "outputId": "5317387a-7878-4e76-84e0-768c28e7fd65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydataset import data\n",
        "\n",
        "# Load the biopsy dataset\n",
        "biopsy_data = data('biopsy')\n",
        "\n",
        "# Display the first few rows\n",
        "print(biopsy_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMWUx9-lJ4e",
        "outputId": "022e35a8-a48f-412f-8d9f-6fef27c132ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        ID  V1  V2  V3  V4  V5    V6  V7  V8  V9   class\n",
            "1  1000025   5   1   1   1   2   1.0   3   1   1  benign\n",
            "2  1002945   5   4   4   5   7  10.0   3   2   1  benign\n",
            "3  1015425   3   1   1   1   2   2.0   3   1   1  benign\n",
            "4  1016277   6   8   8   1   3   4.0   3   7   1  benign\n",
            "5  1017023   4   1   1   3   2   1.0   3   1   1  benign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pydataset statsmodels seaborn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vsBn3-JbveAi",
        "outputId": "32a2fe4c-4d74-4b86-fdab-2f3e53814839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydataset in /usr/local/lib/python3.10/dist-packages (0.2.0)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.10/dist-packages (0.14.4)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from pydataset) (2.2.2)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.26.4)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.13.1)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (1.0.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels) (24.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->pydataset) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Necessary Libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.experimental import enable_iterative_imputer  # noqa: F401\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (confusion_matrix, classification_report,\n",
        "                             roc_auc_score, roc_curve, accuracy_score,\n",
        "                             precision_score, recall_score, f1_score)\n",
        "from sklearn.pipeline import Pipeline\n",
        "import statsmodels.api as sm\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# Suppress warnings for clean output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create Results Directory\n",
        "results_dir = 'results'\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "# -----------------------------------\n",
        "\n",
        "from pydataset import data\n",
        "\n",
        "# Load the biopsy dataset\n",
        "biopsy_data = data('biopsy')\n",
        "\n",
        "# Display initial data overview\n",
        "print(\"Initial Data Overview:\")\n",
        "print(biopsy_data.head())\n",
        "\n",
        "# Handle missing values in V6 (Bare Nuclei) using Iterative Imputer (MICE)\n",
        "# Convert V6 to numeric, coercing errors to NaN\n",
        "biopsy_data['V6'] = pd.to_numeric(biopsy_data['V6'], errors='coerce')\n",
        "\n",
        "# Initialize IterativeImputer\n",
        "imputer = IterativeImputer(random_state=42)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(biopsy_data.drop(['class', 'ID'], axis=1)),\n",
        "                         columns=biopsy_data.drop(['class', 'ID'], axis=1).columns)\n",
        "\n",
        "# Reattach the target variable\n",
        "X_imputed['class'] = biopsy_data['class'].values\n",
        "\n",
        "# Encode the target variable: 'benign' = 0, 'malignant' = 1\n",
        "X_imputed['class'] = X_imputed['class'].map({'benign': 0, 'malignant': 1})\n",
        "\n",
        "# Verify no missing values remain\n",
        "print(\"\\nMissing Values After Imputation:\")\n",
        "print(X_imputed.isnull().sum())\n",
        "\n",
        "# Split features and target\n",
        "X = X_imputed.drop(['class'], axis=1)\n",
        "y = X_imputed['class']\n",
        "\n",
        "# Feature Names\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "# 2. Exploratory Data Analysis (EDA)\n",
        "# -----------------------------------\n",
        "\n",
        "# Descriptive Statistics\n",
        "descriptive_stats = X.describe().T\n",
        "descriptive_stats['Variance'] = X.var()\n",
        "descriptive_stats['Coefficient of Variation'] = descriptive_stats['std'] / descriptive_stats['mean']\n",
        "descriptive_stats = descriptive_stats[['mean', '50%', 'std', 'Variance', 'Coefficient of Variation']]\n",
        "descriptive_stats.rename(columns={'50%': 'Median'}, inplace=True)\n",
        "\n",
        "# Save Descriptive Statistics Table\n",
        "descriptive_stats.to_csv(os.path.join(results_dir, 'descriptive_statistics.csv'))\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "print(descriptive_stats)\n",
        "\n",
        "# Visualizations Directory\n",
        "viz_dir = os.path.join(results_dir, 'visualizations')\n",
        "if not os.path.exists(viz_dir):\n",
        "    os.makedirs(viz_dir)\n",
        "\n",
        "# Histograms and Density Plots\n",
        "for feature in feature_names:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data=X_imputed, x=feature, hue='class', kde=True, stat=\"density\", common_norm=False, palette='coolwarm')\n",
        "    plt.title(f'Distribution of {feature} by Class')\n",
        "    plt.xlabel(feature)\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend(['Benign', 'Malignant'])\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(viz_dir, f'histogram_density_{feature}.png'))\n",
        "    plt.close()\n",
        "\n",
        "# Pairwise Scatter Plot Matrix\n",
        "sns.pairplot(X_imputed, vars=feature_names, hue='class', palette='coolwarm', diag_kind='kde')\n",
        "plt.suptitle('Pairwise Scatter Plot Matrix', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'pairwise_scatter_matrix.png'))\n",
        "plt.close()\n",
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr = X.corr()\n",
        "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap='coolwarm', square=True)\n",
        "plt.title('Correlation Heatmap of Features')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'correlation_heatmap.png'))\n",
        "plt.close()\n",
        "\n",
        "# 3. Data Transformation\n",
        "# ------------------------\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=feature_names)\n",
        "\n",
        "# Box-Cox Transformation for skewed features\n",
        "# Box-Cox requires all data to be positive, check and adjust if necessary\n",
        "pt = PowerTransformer(method='box-cox', standardize=False)\n",
        "\n",
        "# Check for features with non-positive values\n",
        "positive_features = X_scaled.columns[(X_scaled > 0).all()]\n",
        "skewed_features = X_scaled[positive_features].skew().abs()\n",
        "skewed_features = skewed_features[skewed_features > 1].index.tolist()\n",
        "\n",
        "# Apply Box-Cox transformation to skewed features\n",
        "if skewed_features:\n",
        "    X_scaled[skewed_features] = pt.fit_transform(X_scaled[skewed_features])\n",
        "    print(f\"\\nBox-Cox Transformation applied to: {skewed_features}\")\n",
        "\n",
        "# 4. Feature Variability Measures\n",
        "# --------------------------------\n",
        "\n",
        "# Compute Variance and Coefficient of Variation for each feature\n",
        "variance = X.var()\n",
        "cv = variance / X.mean()\n",
        "\n",
        "# Note: Variance and CV are per-feature statistics and should not be added as per-sample columns.\n",
        "# Instead, they can be used separately for analysis.\n",
        "\n",
        "# Save Variability Measures\n",
        "variability_measures = pd.DataFrame({'Feature': feature_names,\n",
        "                                    'Variance': variance.values,\n",
        "                                    'Coefficient of Variation': cv.values})\n",
        "variability_measures.to_csv(os.path.join(results_dir, 'feature_variability.csv'), index=False)\n",
        "print(\"\\nFeature Variability Measures:\")\n",
        "print(variability_measures)\n",
        "\n",
        "# 5. Train-Test Split\n",
        "# ---------------------\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled,\n",
        "                                                    y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    stratify=y,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# 6. Objective 1: Modeling Non-Linear Relationships with Kernel Methods\n",
        "# ------------------------------------------------------------------------\n",
        "\n",
        "# Define the SVM pipeline\n",
        "svm_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('svm', SVC(kernel='rbf', probability=True, random_state=42))\n",
        "])\n",
        "\n",
        "# Define hyperparameter grid for GridSearchCV\n",
        "param_grid_svm = {\n",
        "    'svm__C': [0.1, 1, 10, 100],\n",
        "    'svm__gamma': [0.001, 0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid_svm = GridSearchCV(svm_pipeline,\n",
        "                        param_grid=param_grid_svm,\n",
        "                        cv=cv_strategy,\n",
        "                        scoring='accuracy',\n",
        "                        n_jobs=-1,\n",
        "                        verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "best_params_svm = grid_svm.best_params_\n",
        "print(\"\\nBest Parameters for SVM:\")\n",
        "print(best_params_svm)\n",
        "\n",
        "# Best estimator\n",
        "best_svm = grid_svm.best_estimator_\n",
        "\n",
        "# Predictions on Test Set\n",
        "y_pred_svm = best_svm.predict(X_test)\n",
        "y_proba_svm = best_svm.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm = f1_score(y_test, y_pred_svm)\n",
        "auc_svm = roc_auc_score(y_test, y_proba_svm)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix_svm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
        "plt.title('Confusion Matrix - SVM with RBF Kernel')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'confusion_matrix_svm.png'))\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "fpr_svm, tpr_svm, _ = roc_curve(y_test, y_proba_svm)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr_svm, tpr_svm, label=f'SVM (AUC = {auc_svm:.2f})', color='blue')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title('ROC Curve - SVM with RBF Kernel')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'roc_curve_svm.png'))\n",
        "plt.close()\n",
        "\n",
        "# Classification Report\n",
        "report_svm = classification_report(y_test, y_pred_svm, target_names=['Benign', 'Malignant'])\n",
        "print(\"\\nClassification Report - SVM:\")\n",
        "print(report_svm)\n",
        "\n",
        "# Save Classification Report\n",
        "with open(os.path.join(results_dir, 'classification_report_svm.txt'), 'w') as f:\n",
        "    f.write(report_svm)\n",
        "\n",
        "# 7. Objective 2: Feature Selection with Lasso Regularization\n",
        "# -------------------------------------------------------------\n",
        "\n",
        "# Initialize Logistic Regression with L1 penalty (Lasso)\n",
        "logreg_lasso = LogisticRegression(penalty='l1',\n",
        "                                  solver='saga',\n",
        "                                  max_iter=5000,\n",
        "                                  random_state=42)\n",
        "\n",
        "# Define hyperparameter grid for C (inverse of regularization strength)\n",
        "param_grid_lasso = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_lasso = GridSearchCV(logreg_lasso,\n",
        "                          param_grid=param_grid_lasso,\n",
        "                          cv=cv_strategy,\n",
        "                          scoring='accuracy',\n",
        "                          n_jobs=-1,\n",
        "                          verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "grid_lasso.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "best_params_lasso = grid_lasso.best_params_\n",
        "print(\"\\nBest Parameters for Lasso Logistic Regression:\")\n",
        "print(best_params_lasso)\n",
        "\n",
        "# Best estimator\n",
        "best_lasso = grid_lasso.best_estimator_\n",
        "\n",
        "# Feature Selection: Non-zero coefficients\n",
        "lasso_coef = pd.Series(best_lasso.coef_[0], index=X_train.columns)\n",
        "selected_features = lasso_coef[lasso_coef != 0].index.tolist()\n",
        "print(\"\\nSelected Features by Lasso:\")\n",
        "print(selected_features)\n",
        "\n",
        "# Predictions on Test Set\n",
        "y_pred_lasso = best_lasso.predict(X_test)\n",
        "y_proba_lasso = best_lasso.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluation Metrics\n",
        "accuracy_lasso = accuracy_score(y_test, y_pred_lasso)\n",
        "precision_lasso = precision_score(y_test, y_pred_lasso)\n",
        "recall_lasso = recall_score(y_test, y_pred_lasso)\n",
        "f1_lasso = f1_score(y_test, y_pred_lasso)\n",
        "auc_lasso = roc_auc_score(y_test, y_proba_lasso)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix_lasso = confusion_matrix(y_test, y_pred_lasso)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(conf_matrix_lasso, annot=True, fmt='d', cmap='Greens', cbar=False,\n",
        "            xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])\n",
        "plt.title('Confusion Matrix - Lasso Logistic Regression')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'confusion_matrix_lasso.png'))\n",
        "plt.close()\n",
        "\n",
        "# ROC Curve\n",
        "fpr_lasso, tpr_lasso, _ = roc_curve(y_test, y_proba_lasso)\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(fpr_lasso, tpr_lasso, label=f'Lasso Logistic Regression (AUC = {auc_lasso:.2f})', color='green')\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.title('ROC Curve - Lasso Logistic Regression')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend(loc='lower right')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(viz_dir, 'roc_curve_lasso.png'))\n",
        "plt.close()\n",
        "\n",
        "# Classification Report\n",
        "report_lasso = classification_report(y_test, y_pred_lasso, target_names=['Benign', 'Malignant'])\n",
        "print(\"\\nClassification Report - Lasso Logistic Regression:\")\n",
        "print(report_lasso)\n",
        "\n",
        "# Save Classification Report\n",
        "with open(os.path.join(results_dir, 'classification_report_lasso.txt'), 'w') as f:\n",
        "    f.write(report_lasso)\n",
        "\n",
        "# Save Selected Features and Coefficients\n",
        "lasso_features_df = lasso_coef[lasso_coef != 0].reset_index()\n",
        "lasso_features_df.columns = ['Feature', 'Coefficient']\n",
        "lasso_features_df.to_csv(os.path.join(results_dir, 'lasso_selected_features.csv'), index=False)\n",
        "\n",
        "# 8. Objective 3: Assessing the Impact of Feature Variability\n",
        "# ---------------------------------------------------------------\n",
        "\n",
        "# Since Variance and CV are per-feature statistics, they cannot be directly added as per-sample features.\n",
        "# Instead, we can analyze their relationship with feature importance or use them in a separate analysis.\n",
        "\n",
        "# Example Approach:\n",
        "# - Correlate the CV of features with their coefficients in the Lasso model to assess if more variable features are more predictive.\n",
        "\n",
        "# Calculate correlation between CV and absolute Lasso coefficients\n",
        "cv_values = variability_measures.set_index('Feature').loc[selected_features, 'Coefficient of Variation']\n",
        "lasso_coefficients = lasso_features_df.set_index('Feature').loc[selected_features, 'Coefficient']\n",
        "\n",
        "# Create a DataFrame for correlation analysis\n",
        "correlation_df = pd.DataFrame({\n",
        "    'CV': cv_values,\n",
        "    'Lasso Coefficient': lasso_coefficients.abs()\n",
        "})\n",
        "\n",
        "# Compute correlation\n",
        "correlation = correlation_df.corr().iloc[0, 1]\n",
        "print(f\"\\nCorrelation between CV and Absolute Lasso Coefficients: {correlation:.2f}\")\n",
        "\n",
        "# Save Correlation Analysis\n",
        "correlation_df.to_csv(os.path.join(results_dir, 'cv_vs_lasso_coefficients.csv'))\n",
        "with open(os.path.join(results_dir, 'cv_vs_lasso_coefficients.txt'), 'w') as f:\n",
        "    f.write(f\"Correlation between CV and Absolute Lasso Coefficients: {correlation:.2f}\\n\")\n",
        "\n",
        "# Alternatively, perform a regression analysis\n",
        "# Regress Lasso coefficients on CV\n",
        "X_corr = sm.add_constant(correlation_df['CV'])\n",
        "model_corr = sm.OLS(correlation_df['Lasso Coefficient'], X_corr).fit()\n",
        "print(\"\\nRegression Analysis between CV and Absolute Lasso Coefficients:\")\n",
        "print(model_corr.summary())\n",
        "\n",
        "# Save Regression Analysis Summary\n",
        "with open(os.path.join(results_dir, 'regression_cv_lasso_summary.txt'), 'w') as f:\n",
        "    f.write(model_corr.summary().as_text())\n",
        "\n",
        "# 9. Comparison of Models\n",
        "# -------------------------\n",
        "# ... [Previous code remains the same up to the Regression Analysis in Objective 3] ...\n",
        "\n",
        "# 9. Comparison of Models\n",
        "# -------------------------\n",
        "\n",
        "# Since we only have performance metrics for SVM and Lasso Logistic Regression,\n",
        "# we will update the model comparison accordingly.\n",
        "\n",
        "# Create a DataFrame to compare model performances\n",
        "model_comparison = pd.DataFrame({\n",
        "    'Model': ['SVM with RBF Kernel', 'Lasso Logistic Regression'],\n",
        "    'Accuracy': [accuracy_svm, accuracy_lasso],\n",
        "    'Precision': [precision_svm, precision_lasso],\n",
        "    'Recall': [recall_svm, recall_lasso],\n",
        "    'F1-Score': [f1_svm, f1_lasso],\n",
        "    'AUC': [auc_svm, auc_lasso]\n",
        "})\n",
        "\n",
        "# Format metrics for display\n",
        "model_comparison_display = model_comparison.copy()\n",
        "model_comparison_display['Accuracy'] = model_comparison_display['Accuracy'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "model_comparison_display['Precision'] = model_comparison_display['Precision'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "model_comparison_display['Recall'] = model_comparison_display['Recall'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "model_comparison_display['F1-Score'] = model_comparison_display['F1-Score'].apply(lambda x: f\"{x*100:.2f}%\")\n",
        "model_comparison_display['AUC'] = model_comparison_display['AUC'].apply(lambda x: f\"{x:.2f}\")\n",
        "\n",
        "# Save Model Comparison Table\n",
        "model_comparison_display.to_csv(os.path.join(results_dir, 'model_comparison.csv'), index=False)\n",
        "\n",
        "# Plot Model Comparison\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC']\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.barplot(x='Model', y=metric, data=model_comparison, palette='viridis')\n",
        "    plt.title(f'Comparison of Models: {metric}')\n",
        "    plt.ylim(0, 1.1)\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel(metric)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(viz_dir, f'model_comparison_{metric.lower()}.png'))\n",
        "    plt.close()\n",
        "\n",
        "# 10. Save All Tables and Reports\n",
        "# --------------------------------\n",
        "\n",
        "# Save Descriptive Statistics\n",
        "descriptive_stats.to_csv(os.path.join(results_dir, 'descriptive_statistics.csv'))\n",
        "\n",
        "# Save Feature Variability Measures\n",
        "variability_measures.to_csv(os.path.join(results_dir, 'feature_variability.csv'), index=False)\n",
        "\n",
        "# Save Selected Features from Lasso\n",
        "lasso_features_df.to_csv(os.path.join(results_dir, 'lasso_selected_features.csv'), index=False)\n",
        "\n",
        "# Save Model Comparison Table\n",
        "model_comparison.to_csv(os.path.join(results_dir, 'model_comparison_full.csv'), index=False)\n",
        "\n",
        "# 11. Summary of Results\n",
        "# ------------------------\n",
        "\n",
        "# Print Model Comparison\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(model_comparison_display)\n",
        "\n",
        "# 12. Conclusion\n",
        "# ----------------\n",
        "\n",
        "print(\"\\nAll models have been trained and evaluated. Results and visualizations have been saved in the 'results' folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AvM7Wk80wuJW",
        "outputId": "2fe26cd3-bb9e-4451-8cba-4ddd348ea834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Data Overview:\n",
            "        ID  V1  V2  V3  V4  V5    V6  V7  V8  V9   class\n",
            "1  1000025   5   1   1   1   2   1.0   3   1   1  benign\n",
            "2  1002945   5   4   4   5   7  10.0   3   2   1  benign\n",
            "3  1015425   3   1   1   1   2   2.0   3   1   1  benign\n",
            "4  1016277   6   8   8   1   3   4.0   3   7   1  benign\n",
            "5  1017023   4   1   1   3   2   1.0   3   1   1  benign\n",
            "\n",
            "Missing Values After Imputation:\n",
            "V1       0\n",
            "V2       0\n",
            "V3       0\n",
            "V4       0\n",
            "V5       0\n",
            "V6       0\n",
            "V7       0\n",
            "V8       0\n",
            "V9       0\n",
            "class    0\n",
            "dtype: int64\n",
            "\n",
            "Descriptive Statistics:\n",
            "        mean  Median       std   Variance  Coefficient of Variation\n",
            "V1  4.417740     4.0  2.815741   7.928395                  0.637371\n",
            "V2  3.134478     1.0  3.051459   9.311403                  0.973514\n",
            "V3  3.207439     1.0  2.971913   8.832265                  0.926569\n",
            "V4  2.806867     1.0  2.855379   8.153191                  1.017283\n",
            "V5  3.216023     2.0  2.214300   4.903124                  0.688521\n",
            "V6  3.526567     1.0  3.618696  13.094962                  1.026124\n",
            "V7  3.437768     3.0  2.438364   5.945620                  0.709287\n",
            "V8  2.866953     1.0  3.053634   9.324680                  1.065115\n",
            "V9  1.589413     1.0  1.715078   2.941492                  1.079063\n",
            "\n",
            "Feature Variability Measures:\n",
            "  Feature   Variance  Coefficient of Variation\n",
            "0      V1   7.928395                  1.794672\n",
            "1      V2   9.311403                  2.970639\n",
            "2      V3   8.832265                  2.753681\n",
            "3      V4   8.153191                  2.904730\n",
            "4      V5   4.903124                  1.524592\n",
            "5      V6  13.094962                  3.713232\n",
            "6      V7   5.945620                  1.729500\n",
            "7      V8   9.324680                  3.252471\n",
            "8      V9   2.941492                  1.850678\n",
            "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
            "\n",
            "Best Parameters for SVM:\n",
            "{'svm__C': 10, 'svm__gamma': 0.01}\n",
            "\n",
            "Classification Report - SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.98      0.97      0.97        92\n",
            "   Malignant       0.94      0.96      0.95        48\n",
            "\n",
            "    accuracy                           0.96       140\n",
            "   macro avg       0.96      0.96      0.96       140\n",
            "weighted avg       0.96      0.96      0.96       140\n",
            "\n",
            "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
            "\n",
            "Best Parameters for Lasso Logistic Regression:\n",
            "{'C': 0.1}\n",
            "\n",
            "Selected Features by Lasso:\n",
            "['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9']\n",
            "\n",
            "Classification Report - Lasso Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Benign       0.96      0.97      0.96        92\n",
            "   Malignant       0.94      0.92      0.93        48\n",
            "\n",
            "    accuracy                           0.95       140\n",
            "   macro avg       0.95      0.94      0.94       140\n",
            "weighted avg       0.95      0.95      0.95       140\n",
            "\n",
            "\n",
            "Correlation between CV and Absolute Lasso Coefficients: 0.43\n",
            "\n",
            "Regression Analysis between CV and Absolute Lasso Coefficients:\n",
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:      Lasso Coefficient   R-squared:                       0.189\n",
            "Model:                            OLS   Adj. R-squared:                  0.073\n",
            "Method:                 Least Squares   F-statistic:                     1.633\n",
            "Date:                Mon, 02 Dec 2024   Prob (F-statistic):              0.242\n",
            "Time:                        05:15:27   Log-Likelihood:                -2.2309\n",
            "No. Observations:                   9   AIC:                             8.462\n",
            "Df Residuals:                       7   BIC:                             8.856\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.0469      0.412     -0.114      0.912      -1.021       0.927\n",
            "CV             0.2018      0.158      1.278      0.242      -0.172       0.575\n",
            "==============================================================================\n",
            "Omnibus:                        1.979   Durbin-Watson:                   1.958\n",
            "Prob(Omnibus):                  0.372   Jarque-Bera (JB):                1.102\n",
            "Skew:                           0.574   Prob(JB):                        0.576\n",
            "Kurtosis:                       1.727   Cond. No.                         10.4\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "\n",
            "Model Comparison:\n",
            "                       Model Accuracy Precision  Recall F1-Score   AUC\n",
            "0        SVM with RBF Kernel   96.43%    93.88%  95.83%   94.85%  0.99\n",
            "1  Lasso Logistic Regression   95.00%    93.62%  91.67%   92.63%  0.99\n",
            "\n",
            "All models have been trained and evaluated. Results and visualizations have been saved in the 'results' folder.\n"
          ]
        }
      ]
    }
  ]
}